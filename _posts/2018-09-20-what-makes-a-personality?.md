Reading Jon Bois’ "17776" inspired me to think more about how Nine, Ten, and Juice developed their personalities. A simple answer would be that they talk and type like humans of their time period would: this explains why Juice never uses capitalization and rarely uses punctuation, decorating his conversations with obscenities and slang. I found Juice hilarious and relatable,  which makes sense considering that he would be closer to my age. 

However, I began to wonder how three satellites which had been around for the same amount of time (60 years is virtually meaningless compared to the 17,000) and had taken in almost identical information over the course of their “lives” would have drastically different personalities. And in a more general sense, I began to wonder how AI would develop a specific personality in general.

I remembered that in 2016, Microsoft launched a chatbot on Twitter which had been trained to act like a nineteen-year-old woman. Her name was Tay, and within just 24 hours they had to shut her down because just a day’s worth of interaction with Twitter users had turned into a neo-Nazi, sex-obsessed “monster.” According to [this article](https://www.technologyreview.com/s/610634/microsofts-neo-nazi-sexbot-was-a-great-lesson-for-makers-of-ai-assistants/) from MIT Technology Review, it was extremely easy to teach Tay offensive phrases and ideology. In some way, just like people, Tay developed a personality based on her environment, and based on the ideas that she was fed from those around her. [This article](https://www.technologyreview.com/s/601111/why-microsoft-accidentally-unleashed-a-neo-nazi-sexbot/) explains how she was conditioned a bit more: “Tay’s training set consisted of a bunch of nasty tweets, so her artificial brain slurped them up and she spit out what seemed like proper rejoinders.” All it took for Tay to become a racist was a day’s worth of interaction with people, and she simply spit back out what had been given to her.

Would it even be possible for artificial intelligence to develop a personality independently, without being coded to respond in specific ways? Tay was trained to act “sassy,” and to use particular phrasing and slang, with millennials in mind. She used data from interacting with other Twitter users in order to learn more, but she was still programmed with a baseline personality. Nine, Ten, and Juice were not coded with personality, but they simply observed Earth and recorded all of that data. From all of that information, they somehow developed their own distinct personalities. Now, of course “17776” was a fictional interpretation of this idea. But it still raises questions about AI. 

AI keeps getting more and more convincing. In a recently released video game, "Detroit: Become Human," AI has advanced enough to look completely human, to act completely human, and eventually the androids in the game rise up against humans because they want to be recognized as people and gain rights. They truly seem to feel just as humans do. Will there be a time where this actually happens, and the definition of personhood will change? If Nine, Ten, and Juice all developed personalities as a result of years of experience observing Earth, how is that so different from how humans develop personalities? Is sentience enough?
